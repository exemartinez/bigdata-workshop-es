{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIGO - Part Optional\n",
    "\n",
    "Here we check the accuracy which with the predictions were made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the spark context and tools for processing the stored rows.\n",
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "# initialise sparkContext\n",
    "spark = SparkSession.builder \\\n",
    "    .master('local') \\\n",
    "    .appName('myAppName') \\\n",
    "    .config('spark.executor.memory', '12gb') \\\n",
    "    .config(\"spark.cores.max\", \"2\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# using SQLContext to read parquet file\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df = spark.read.parquet('/dataset/gw_gravity_spy_dataframe_prediction')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_df = sqlContext.read.parquet('/dataset/gw_gravity_spy_dataframe')\n",
    "test_set= parquet_df.where(parquet_df['sample_type']=='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df.select('prediction').where(predict_df.prediction == 1).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1179"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df.select('prediction').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1179"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['features', 'rawPrediction', 'prediction']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['event_time',\n",
       " 'ifo',\n",
       " 'peak_time',\n",
       " 'peak_time_ns',\n",
       " 'start_time',\n",
       " 'start_time_ns',\n",
       " 'duration',\n",
       " 'search',\n",
       " 'process_id',\n",
       " 'event_id',\n",
       " 'peak_frequency',\n",
       " 'central_freq',\n",
       " 'bandwidth',\n",
       " 'channel',\n",
       " 'amplitude',\n",
       " 'snr',\n",
       " 'confidence',\n",
       " 'chisq',\n",
       " 'chisq_dof',\n",
       " 'param_one_name',\n",
       " 'param_one_value',\n",
       " 'url1',\n",
       " 'url2',\n",
       " 'url3',\n",
       " 'url4',\n",
       " 'png',\n",
       " 'gravityspy_id',\n",
       " 'label',\n",
       " 'sample_type']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['label', 'png']\n",
      "Gravitational Waves: 10\n",
      "['features_original', 'label']\n",
      "Gravitational Waves (after): 10\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "test = test_set.select(\"label\",\"png\")\n",
    "\n",
    "print(test.columns)\n",
    "\n",
    "#Reshaping the labels as \"Chrip\" = \"True\" and all the others as \"False\"; Chrips are Gravitational Waves.\n",
    "result = test.where(test.label == \"Chirp\")\n",
    "print(\"Gravitational Waves: {0}\".format(result.count()))\n",
    "\n",
    "test = test.withColumn('gw', (test.label == \"Chirp\"))\n",
    "test = test.drop(\"label\")\n",
    "\n",
    "test = test.withColumn('features_original', test.png)\n",
    "test = test.withColumn('label', test.gw)\n",
    "import pyspark.sql.functions as sf\n",
    "\n",
    "test = test.drop(\"png\")\n",
    "test = test.drop(\"gw\")\n",
    "test_df = test.withColumn('label', (F.col('label') == True).cast('integer'))\n",
    "\n",
    "print(test.columns)\n",
    "\n",
    "result = test.where(test.label == 1)\n",
    "print(\"Gravitational Waves (after): {0}\".format(result.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['features', 'rawPrediction', 'prediction', 'features_original', 'label']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here we must add the 'label' part to each prediction\n",
    "from pyspark.sql.functions import monotonically_increasing_id, row_number\n",
    "from pyspark.sql import Window\n",
    "\n",
    "# since there is no common column between these two dataframes add row_index so that it can be joined\n",
    "predict_df=predict_df.withColumn('row_index', row_number().over(Window.orderBy(monotonically_increasing_id())))\n",
    "test_df=test_df.withColumn('row_index', row_number().over(Window.orderBy(monotonically_increasing_id())))\n",
    "\n",
    "predict_df = predict_df.join(test_df, on=[\"row_index\"]).drop(\"row_index\")\n",
    "#predict_df.show()\n",
    "\n",
    "#predict_df = predict_df.withColumn(\"label\", test_df.label)\n",
    "predict_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[features: vector, rawPrediction: vector, prediction: double, label: int]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df.drop('features_original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we add the model to the context, just in case we might need it.\n",
    "from pyspark.ml.classification import LinearSVCModel\n",
    "\n",
    "lsvcModel =  LinearSVCModel.load(\"/app/gw/lsvc.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "area under ROC curve: 0.772797\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "evaluation = evaluator.evaluate(predict_df)\n",
    "\n",
    "print(\"area under ROC curve: %f\" % evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "igwn-py37",
   "language": "python",
   "name": "igwn-py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
